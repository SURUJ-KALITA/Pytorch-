{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AChSeSa4HRX",
        "outputId": "6b298503-6620-4c34-d073-4a58b7dc2028"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3.1+cu121\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9A4nR7d4t0W",
        "outputId": "e6b75f51-13d0-4180-a18d-21f6f39a1fc7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Aug 25 06:31:57 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8              12W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5vNmVVq4PNo",
        "outputId": "c2d8c29b-c1e4-48ab-9e26-1d9ad1a052b6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_1 = torch.tensor([1., 2., 3.])\n",
        "tensor_2 = torch.tensor([4., 5., 6.])\n",
        "\n",
        "print(tensor_1 + tensor_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C66nnYhh4YxT",
        "outputId": "af2520b5-5243-4a1a-8c61-c1886caa1976"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5., 7., 9.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_1 = tensor_1.to(\"cuda\")\n",
        "tensor_2 = tensor_2.to(\"cuda\")\n",
        "\n",
        "print(tensor_1 + tensor_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ydSCpeK4dbC",
        "outputId": "9bbe6904-d6ad-48be-9f23-94bbc9173a03"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5., 7., 9.], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Single Runtime gpu"
      ],
      "metadata": {
        "id": "LRvf141x5kGw"
      }
    },
    {
      "source": [
        "X_train = torch.tensor([\n",
        "    [-1.2, 3.1],\n",
        "    [-0.9, 2.9],\n",
        "    [-0.5, 2.6],\n",
        "    [2.3, -1.1],\n",
        "    [2.7, -1.5]\n",
        "])\n",
        "\n",
        "y_train = torch.tensor([0, 0, 0, 1, 1])\n",
        "\n",
        "X_test = torch.tensor([\n",
        "    [-0.8, 2.8],\n",
        "    [2.6, -1.6],\n",
        "])\n",
        "\n",
        "y_test = torch.tensor([0, 1])"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "MuJCSM0i4szj"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class ToyDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.features = X\n",
        "        self.labels = y\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        one_x = self.features[index]\n",
        "        one_y = self.labels[index]\n",
        "        return one_x, one_y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.labels.shape[0]\n",
        "\n",
        "train_ds = ToyDataset(X_train, y_train)\n",
        "test_ds = ToyDataset(X_test, y_test)"
      ],
      "metadata": {
        "id": "uzsuGKKx4f2d"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_ds,\n",
        "    batch_size=2,\n",
        "    shuffle=True,\n",
        "    num_workers=1,\n",
        "    drop_last=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_ds,\n",
        "    batch_size=2,\n",
        "    shuffle=False,\n",
        "    num_workers=1\n",
        ")"
      ],
      "metadata": {
        "id": "5a-OQ1Qr5ur6"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(torch.nn.Module):\n",
        "    def __init__(self, num_inputs, num_outputs):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers = torch.nn.Sequential(\n",
        "\n",
        "            # 1st hidden layer\n",
        "            torch.nn.Linear(num_inputs, 30),\n",
        "            torch.nn.ReLU(),\n",
        "\n",
        "            # 2nd hidden layer\n",
        "            torch.nn.Linear(30, 20),\n",
        "            torch.nn.ReLU(),\n",
        "\n",
        "            # output layer\n",
        "            torch.nn.Linear(20, num_outputs),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.layers(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "wLSC9srH5vGY"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = NeuralNetwork(num_inputs=2, num_outputs=2)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # NEW\n",
        "model = model.to(device) # NEW\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.5)\n",
        "\n",
        "num_epochs = 3\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    model.train()\n",
        "    for batch_idx, (features, labels) in enumerate(train_loader):\n",
        "\n",
        "        features, labels = features.to(device), labels.to(device) # NEW\n",
        "        logits = model(features)\n",
        "        loss = F.cross_entropy(logits, labels) # Loss function\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        ### LOGGING\n",
        "        print(f\"Epoch: {epoch+1:03d}/{num_epochs:03d}\"\n",
        "              f\" | Batch {batch_idx:03d}/{len(train_loader):03d}\"\n",
        "              f\" | Train/Val Loss: {loss:.2f}\")\n",
        "\n",
        "    model.eval()\n",
        "    # Optional model evaluation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bhtk980d5vI7",
        "outputId": "f090606b-ec41-4942-beea-483acfaf9c34"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001/003 | Batch 000/002 | Train/Val Loss: 0.75\n",
            "Epoch: 001/003 | Batch 001/002 | Train/Val Loss: 0.65\n",
            "Epoch: 002/003 | Batch 000/002 | Train/Val Loss: 0.44\n",
            "Epoch: 002/003 | Batch 001/002 | Train/Val Loss: 0.13\n",
            "Epoch: 003/003 | Batch 000/002 | Train/Val Loss: 0.03\n",
            "Epoch: 003/003 | Batch 001/002 | Train/Val Loss: 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_accuracy(model, dataloader, device):\n",
        "\n",
        "    model = model.eval()\n",
        "    correct = 0.0\n",
        "    total_examples = 0\n",
        "\n",
        "    for idx, (features, labels) in enumerate(dataloader):\n",
        "\n",
        "        features, labels = features.to(device), labels.to(device) # New\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(features)\n",
        "\n",
        "        predictions = torch.argmax(logits, dim=1)\n",
        "        compare = labels == predictions\n",
        "        correct += torch.sum(compare)\n",
        "        total_examples += len(compare)\n",
        "\n",
        "    return (correct / total_examples).item()"
      ],
      "metadata": {
        "id": "4gJKJpPs5vMZ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compute_accuracy(model, train_loader, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rz5qQewL5vPu",
        "outputId": "1258fb57-ef7f-4cc6-adac-a069d7717360"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compute_accuracy(model, test_loader, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_zSFgDf594i",
        "outputId": "33edb418-7d18-4531-e642-07a64b749e1b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiple GPU"
      ],
      "metadata": {
        "id": "gbVSgMHk6KxT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# NEW imports:\n",
        "import os\n",
        "import torch.multiprocessing as mp\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from torch.nn.parallel import DistributedDataParallel as DDP\n",
        "from torch.distributed import init_process_group, destroy_process_group\n",
        "\n",
        "\n",
        "# NEW: function to initialize a distributed process group (1 process / GPU)\n",
        "# this allows communication among processes\n",
        "def ddp_setup(rank, world_size):\n",
        "\n",
        "\n",
        "    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
        "    # any free port on the machine\n",
        "    os.environ[\"MASTER_PORT\"] = \"3000\"\n",
        "\n",
        "    # initialize process group\n",
        "    # Windows users may have to use \"gloo\" instead of \"nccl\" as backend\n",
        "    # nccl: NVIDIA Collective Communication Library\n",
        "    init_process_group(backend=\"nccl\", rank=rank, world_size=world_size)\n",
        "    torch.cuda.set_device(rank)\n",
        "\n",
        "\n",
        "class ToyDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.features = X\n",
        "        self.labels = y\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        one_x = self.features[index]\n",
        "        one_y = self.labels[index]\n",
        "        return one_x, one_y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.labels.shape[0]\n",
        "\n",
        "\n",
        "class NeuralNetwork(torch.nn.Module):\n",
        "    def __init__(self, num_inputs, num_outputs):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers = torch.nn.Sequential(\n",
        "            # 1st hidden layer\n",
        "            torch.nn.Linear(num_inputs, 30),\n",
        "            torch.nn.ReLU(),\n",
        "\n",
        "            # 2nd hidden layer\n",
        "            torch.nn.Linear(30, 20),\n",
        "            torch.nn.ReLU(),\n",
        "\n",
        "            # output layer\n",
        "            torch.nn.Linear(20, num_outputs),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.layers(x)\n",
        "        return logits\n",
        "\n",
        "\n",
        "def prepare_dataset():\n",
        "    X_train = torch.tensor([\n",
        "        [-1.2, 3.1],\n",
        "        [-0.9, 2.9],\n",
        "        [-0.5, 2.6],\n",
        "        [2.3, -1.1],\n",
        "        [2.7, -1.5]\n",
        "    ])\n",
        "    y_train = torch.tensor([0, 0, 0, 1, 1])\n",
        "\n",
        "    X_test = torch.tensor([\n",
        "        [-0.8, 2.8],\n",
        "        [2.6, -1.6],\n",
        "    ])\n",
        "    y_test = torch.tensor([0, 1])\n",
        "\n",
        "    train_ds = ToyDataset(X_train, y_train)\n",
        "    test_ds = ToyDataset(X_test, y_test)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        dataset=train_ds,\n",
        "        batch_size=2,\n",
        "        shuffle=False,  # NEW: False because of DistributedSampler below\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "        # NEW: chunk batches across GPUs without overlapping samples:\n",
        "        sampler=DistributedSampler(train_ds)  # NEW\n",
        "    )\n",
        "    test_loader = DataLoader(\n",
        "        dataset=test_ds,\n",
        "        batch_size=2,\n",
        "        shuffle=False,\n",
        "    )\n",
        "    return train_loader, test_loader\n",
        "\n",
        "\n",
        "# NEW: wrapper\n",
        "def main(rank, world_size, num_epochs):\n",
        "\n",
        "    ddp_setup(rank, world_size)  # NEW: initialize process groups\n",
        "\n",
        "    train_loader, test_loader = prepare_dataset()\n",
        "    model = NeuralNetwork(num_inputs=2, num_outputs=2)\n",
        "    model.to(rank)\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.5)\n",
        "\n",
        "    model = DDP(model, device_ids=[rank])  # NEW: wrap model with DDP\n",
        "    # the core model is now accessible as model.module\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        model.train()\n",
        "        for features, labels in train_loader:\n",
        "\n",
        "            features, labels = features.to(rank), labels.to(rank)  # New: use rank\n",
        "            logits = model(features)\n",
        "            loss = F.cross_entropy(logits, labels)  # Loss function\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # LOGGING\n",
        "            print(f\"[GPU{rank}] Epoch: {epoch+1:03d}/{num_epochs:03d}\"\n",
        "                  f\" | Batchsize {labels.shape[0]:03d}\"\n",
        "                  f\" | Train/Val Loss: {loss:.2f}\")\n",
        "\n",
        "    model.eval()\n",
        "    train_acc = compute_accuracy(model, train_loader, device=rank)\n",
        "    print(f\"[GPU{rank}] Training accuracy\", train_acc)\n",
        "    test_acc = compute_accuracy(model, test_loader, device=rank)\n",
        "    print(f\"[GPU{rank}] Test accuracy\", test_acc)\n",
        "\n",
        "    destroy_process_group()  # NEW: cleanly exit distributed mode\n",
        "\n",
        "\n",
        "def compute_accuracy(model, dataloader, device):\n",
        "    model = model.eval()\n",
        "    correct = 0.0\n",
        "    total_examples = 0\n",
        "\n",
        "    for idx, (features, labels) in enumerate(dataloader):\n",
        "        features, labels = features.to(device), labels.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(features)\n",
        "        predictions = torch.argmax(logits, dim=1)\n",
        "        compare = labels == predictions\n",
        "        correct += torch.sum(compare)\n",
        "        total_examples += len(compare)\n",
        "    return (correct / total_examples).item()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"PyTorch version:\", torch.__version__)\n",
        "    print(\"CUDA available:\", torch.cuda.is_available())\n",
        "    print(\"Number of GPUs available:\", torch.cuda.device_count())\n",
        "\n",
        "    torch.manual_seed(123)\n",
        "\n",
        "    # NEW: spawn new processes\n",
        "    # note that spawn will automatically pass the rank\n",
        "    num_epochs = 3\n",
        "    world_size = torch.cuda.device_count()\n",
        "    # mp.spawn(main, args=(world_size, num_epochs), nprocs=world_size)\n",
        "    # nprocs=world_size spawns one process per GPU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5pAmXnj597C",
        "outputId": "052d7659-3774-47ef-dcf2-c896374ceed3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.3.1+cu121\n",
            "CUDA available: True\n",
            "Number of GPUs available: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kdolbdeb5vSz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}